\documentclass[12pt]{amsart}
\usepackage{graphicx}
\newcommand{\lik}{\ensuremath{\mathcal{L}}}
\newcommand{\gimli}{\texttt{gimli}}

\begin{document}
\title{Multiscale segmentation of methylation data}
\author{Emanuele Raineri}
\date{\today}
\maketitle

\begin{abstract}
%Since it is possible to decorate the human genome with tracks of numerical
%values produced by methods for measuring all sorts of physico-chemical interactions 
%(chromatin modification,
%Hi-C, whole genome bisulfite sequencing, and more), 
%it is useful to implement software 
%which can quickly summarize the data and extract patterns to help 
%automating at least  part of the biological analysis. 
In this paper, I show one efficient way of computing 
segmentations of methylation values determined by 
whole genome bisulfite sequencing
A segmentation joins adjacent position
which have similar properties, while the boundary between segments 
indicates more or less abrupt changes
in the signal which might relate to biological mechanisms. 
One salient aspects which must be considered when it comes to 
analyzing methylation dataset is that this epigenetic mark seems 
to have effect at various genomic scales 
(ranging from hundred of bases to megabases), hence a multi scale method 
is called for. 
The probabilistic method I introduce here 
coupled with a known procedure previously
used for copy number detection
can be used to calculate automatic segmentations at different scales.
I also show how this 
kind of statistical modeling is expedient for 
visualization, comparison across samples,
and demarcation of unusual regions in 
order to direct further analysis (i.e. regions with stark variations in the signal).
\end{abstract}

\section{Introduction}

Whole genome Bisulfite sequencing (WGBS) allows measurements of methylation 
status with single base resolution across an entire genome. We now know,
thanks to WGBS and other techniques,  
that this epigenetic mark has a strong local correlation,
in the sense the the methylation status at one position predicts 
very well the levels nearby; this suggests that it should be possible
to build compressed representations of the methylation data in which contiguous loci 
are collected into segments.
This local correlation has been observed many times ( for example
in the Bsmooth paper \cite{bsmooth}) and is confirmed by 
figure~\ref{fig1}. 
%which I computed 
%first selecting at random $10^6$ pairs of  methylated loci; then binning
%them according to the distance between the members of the pair (I considered 20 
%bins corresponding to distance between $0$ and $100$bp,$100$ and $200$bp, 
%etc\dots);
%finally computing for each bin the correlation in methylation values 
%across the pairs contained in it. 

\begin{center}
\begin{figure}\label{fig1}
\includegraphics[width=7cm,angle=270]{out.correla.eps}
\caption{This plot is produced by extracting $1$ million random pairs of CpG loci;
storing the pairs in $20$ different bins  according to the distance between the members
of the pair (from $0-100$ to $1900-2000$); and computing the correlation in each bin,
using the pairs contained in it.}
\end{figure}
\end{center}

Another interesting aspect of methylation is that it possesses some sort of scale 
invariance: variations can be observed both at the level of a single promoter
region (hundred of bases, see for example \cite{methylseekr}) and when looking at stretches
of millions of bases (\cite{largeblocks} ).
This brings about contrasting requirements when analyzing this kind of data: large scale (slow) changes are 
significant and must be looked at, but a rough
running average with a window of many megabases might destroy interesting
local detail. Here I present  a software (\gimli) which computes a multiscale segmentation 
of DNA methylation 
data acquired through WGBS and helps making sense of the data and compare 
it across samples.

A segmentation is a statistical model of a dataset  which takes into account its spatial properties:
in particular, adjacent points with similar properties are grouped together.
In general, when building a statistical model one tries to find a reasonable 
trade off between two 
features  its goodness of fit and its complexity.
In our case these two aspects have a very simple interpretation : both the goodness 
of fit and the complexity increase with the number of segments $N_S$ used to describe the 
methylation data.  
At one extreme, representing the complete dataset with one big segment would 
give a very simple model with, but likely a very bad fit;  
at the other using many segments of length $1$ would give us typically
a well fitting but very complex summary of the data.
The complexity of the model is linked to the typical scale of the segments used
in the sense that if the typical block is very long one needs few of them to 
cover the genomic region under consideration.

\section{The algorithm}

The  input to \texttt{gimli} is a set of $N$ methylated positions 
(CpGs or not, although I will refer to CpGs in the rest of the paper; also in what
follows I will call {\em block} or ,
equivalently, {\em segment}
both a single CpG or a set of contiguous CpGs ) indexed by $j=1,\dots,N$ 
(for human chromosome $1$ and at a 
decent coverage one has $N \approx 2\times 10^6$).

The output is a set of blocks 
covering the initial positions 
such that each block contains CpGs which are similarly
methylated. The strength with which
one imposes the similarity constraint
is controlled by a coarseness parameter $\lambda$.

Internally \texttt{gimli} mantains a list of the current  
segments (indexed by $i=1,\dots,N_S$), 
which at the beginning 
coincides with the loci given in input. 
( i.e.  $N_S=N$ and each block has length $1$). 

The way the program works is by 
scanning repeatedly this list and evaluate whether any pair 
of adjacent blocks can be conveniently merged into one.  
This is decided by checking whether the loss in 
likelihood consequent to the merging is compensated 
(or more than compensated)
by the reduction in complexity achieved by it.

The likelihood of a block is defined as follows: if the
segment coincides with a single locus $i$, one has

\begin{equation}
\lik_i=\log {\overline{n}_i+n_i \choose \overline{n}_i} +
	{\overline{n}_i}\log\hat{\theta}_i+
	n_i\log(1-\hat{\theta}_i)
\end{equation}
\label{loglik}

where

$n_i$ and $\overline{n}_i$ are the converted and unconverted reads respectively 
and

\[\hat{\theta}_i=\frac{\overline{n}_i}{\overline{n}_i+n_i}\]

is the maximum likelihood estimation for the parameter of the binomial process 
which generates $\overline{n}_i$.

If a block contains  more than a single CpG  
( think for concreteness of a segment which includes all the positions from 
$j_1$ to $j_2$ ) $\lik$ is 
computed in a similar way in equation (\ref{loglik}) but for the fact that $\hat{\theta}$ is now
defined as :

\[
\hat{\theta}=\frac{\overline{n}}{n + \overline{n}}
\]

where

\[
\overline{n}=\sum_{j=j_1}^{j_2} \overline{n}_j
\]

and

\[
n=\sum_{j=j_1}^{j_2} n_j
\]


The total likelihood of the segmentation is in turn given by 
$\mathcal{L}=\sum_i\mathcal{L}_i$.

The loss in 
total likelihood that we get if we merge a pair $(i,i+1)$ of 
adjacent segments in one single block is:

\[\mathcal{L}_{i,i+1}-\mathcal{L}_i-\mathcal{L}_{i+1}\]

where $\mathcal{L}_{i,i+1}$ is the likelihood of a segment which includes
all the loci in segments $i$ and $i+1$.
Notice that it can be  $\mathcal{L}_{i,i+1} \leq \mathcal{L}_i+\mathcal{L}_{i+1}$ and hence merging  
can introduce a loss in total 
likelihood. This loss is counterbalanced, though, by the fact the the number 
of segments decreases by $1$. To take into account this decrease in 
complexity we consider an adjusted likelihood change:

\[\Delta  \lik = -\mathcal{L}_i-\mathcal{L}_{i+1}+\mathcal{L}_{i,i+1} + \lambda\]

Once it has computed 
$\Delta  \lik$ for all $i$, the algorithm selects the maximum 
one : if this is positive, it conjoins the corresponding segments into one.

The software repeats the scanning and merging until it is not possible to 
merge any more pair of adjacent segments; in this case depending on what the 
user wants it can either increment $\lambda$ and try again, 
or give up, print the segmentation and exit.

The above procedure is similar to the one
described in the context of copy number variation detection in \cite{vega} 
( which, in turn, us an adaptation 
of a 2 dimensional image analysis algorithm due to Mumford and Shah, 
\cite{mumfordshah}) except that the probabilistic method  described
here is more suitable for analyzing methylation data. This is because it takes into account the
uncertainty with which we know the methylation levels. This is higher when the coverage is low and vice versa.
This has an effect on the decision of merging adjacent blocks. For example in \ref{fig2} I plot
$\Delta  \lik$  (vertical axis)for two segments at $\theta=0.8$ and $\theta=0.45$ measured at different read depth
(horizontal axis).

\begin{figure}\label{fig2}
\includegraphics[width=7cm]{fig2.eps}
\caption{$\Delta  \lik$ at fixed methylation difference depends on read depth.}
\end{figure}


\subsection{sparsity of CpGs}

Methylated sites are irregularly spaced along the genome and the variability 
introduced by the sequencing process usually increases the distance 
between adjacent sites.
To avoid building segments which span long regions where no CpGs exist, one 
can multiply the difference in likelihoods by a sigmoidal penalty term of the
form \[\rho=\frac{D1}{1+\exp(-D_{i,i+1}/D0)}-\frac{D_1}{2}+1\] where $D_{i,i+1}$ is the distance 
between the the rigth end of segment $i$ and the left end of segment $i+1$ and 
$D_0,D_1$ are constants which (looking at figure \ref{corr}) can be reasonably 
set to $D_0=10000,D_1=100$. 

Hence the final expression for the adjusted likelihood change is :

\begin{equation}
\Delta \lik = \rho ( -\mathcal{L}_i-\mathcal{L}_{i+1}+\mathcal{L}_{i,i+1} )  +\lambda
\end{equation}


\subsection{some preliminary results}

First of all I check that the results of the algorithm are reasonable.
In particular, at any given length I want the segments created by gimli to have lower methylation
variability than random segments of the same length extracted from the input dataset. This is the content of
\ref{fig3}.

\begin{figure}\label{fig3}
\includegraphics[width=7cm]{fig3.eps}
\caption{}
\end{figure}

I can now refine quantitatively the assertion that the complexity of the model
is linked to the typical lengths of the segments : as figure \ref{fig4} 
shows the median length of the blocks increases with $\lambda$. This is 
accompanied by a decrease in likelihood of the segments (\ref{fig5})

\begin{figure}\label{fig4}
\includegraphics[width=7cm,angle=270]{boxplot1.eps}
\caption{Median length of blocks is higher at higher $\lambda$s.}
\end{figure}

\begin{figure}\label{fig5}
\includegraphics[width=7cm,angle=270]{boxplot2.eps}
\caption{Likelihood of blocks diminishes with $\lambda$.}
\end{figure}

\section{examples}

While one can verify that the numbers computed by the algorithm are in 
accordance with the description
given in this paper, the purpose of \gimli is to help 
detect automatically interesting
biological patterns in methylation data, and this can't be tested in any 
precise sense. To show that \gimli{} is a useful tool
though, I will give $4$ examples of analyses which can be produced very quickly
using it. 

\subsection{Breakpoints}

First I'll show how the boundary of the segments, also known as the breakpoints
can correspond to landmarks in the genome. To this purpose, I considered the (publicly available)
$4$ Blueprint monocytes \verb=C000S5A1bs=,\verb=C0010KA2bs=,\verb=C001UYA3bs= and \verb=C004SQ51= 
I computed their segmentation for $\lambda=10$ and looked for all the triples of consecutive segments
where 
\begin{itemize}
\item{} the minimum value of the first segment is bigger than $0.25$ plus the maximum vaule
of the second segment and
\item{} the maximum value of the second segment is less than the minimum value of the third
segment minus $0.25$ and
\item{} all the segments contain at least $5$ CpGs.
\item{} they must appear in all the 4 samples
\end{itemize}

These conditions correspond to regions where the methylation goes from high to low to high again.
See for example \ref{fig6} 

In this way I obtain $143$ such triplets. Looking at their central segmentes
(those in a comparatively low methylation states) I find that their median length is
$252$bp (minimum length $39$, maximum $252$). When I intersect this central segments with the Blueprint
annotation, I find than $94$ overlap a known transcript, suggesting that regions with stark 
changes in methylation
might sistematically correspond to regulated partos of the genome.



%\subsection{visualization}

%In figure \ref{ex1} I plotted the methylation in blocks (with $\lambda=1000$) 
%across a region of $1$ for $2$ Blueprint samples
%(G199,G202), together with the raw data.  Although some segments
%correspond to variable strectches, the reduction in complexity achieved by \gimli makes it 
%possible to observe some relevant signal by eye (in this case there is 
%an apparent loss of methylation across the $2$ samples, which are different 
%stages in the hematopoietic process).

%\begin{figure}\label{ex1}
%\includegraphics[width=10cm,angle=270]{G199.G200.G201.G202.chr1.gimli.eps}
%\caption{output of \gimli, for $\lambda=1000$ for two Blueprint samples. The loss of
%methylation is clearly visible.}
%\end{figure}

%\subsection{comparison across samples (DMRs)}

%\gimli  makes it easy to find regions which have different 
%methylations across samples. One needs to find segments 
%from the first and the second batch which intersect spatially
%but correspond to non overlapping intervals of methylation 
%(the maximum value of one 
%segment is less than the minimum of the other).

%Users can fine tune this procedure according to what exactly they 
%are looking for, taking into account that a standard deviation of $0.2$
%on the methylation measurements done with WGBS is not unusual, hence
%DMRs must be substantially separated to avoid confusion with sampling error.

%Also notice that I am not giving any algorithm to compute $p$-values
%or anything of the sort; first of all the credibility of each segment
%is measured by its log likelihood; secondly users can choose statistical
%tests suited to the specific signal (and the specific scale)
%they are considering.

%\begin{figure}\label{ex1}
%\includegraphics[width=10cm,angle=270]{G199.G202.100.200.dmr.eps}
%\caption{Differentially methylated regions : I considered segments 
%(found setting $\lambda=100$) longer than $200$bp 
%corresponding to
%non overlapping intervals of methylation values (ie the maximum value of one 
%segment is less than the minimum of the other).}
%\end{figure}

%\subsection{comparison with other kind of data}

%Many dataset in genomics are naturally expressed as segments. The
%fact that \gimli also generates annotated blocks allows one to
%integrate methylation data with other kind of information easily
%using such packages as, for instance, \texttt{bedtools} (XXX).

%As an example, I consider the set of $5227$ transcription start sites
%(TSSes) on human chromosome $1$. I infer the TSSes from a list of 
%regions used for gene expression quantification by the Blueprint 
%consortium. For each of them, I also consider the RPKM of the corresponding
%gene in the sample $C004GD$. I then compute with \gimli the segmentation
%of the methylation measurements for chromosome $1$ of $C004GD$.

%My intent is to show that the segments overlapping the TSSs
%say something about the transcriptional activity of the nearby gene.
%Accordingly,
%I use \texttt{bedtools} to intersect the list of blocks produced by \gimli
%with the list of transcription start sites; since more than one \gimli
%block can overlap a given TSS (blocks with different $\lambda$s can 
%cover the same region) I choose the largest segment covering the TSS
%with the constraint thet the maximum and minimum value of methylation
%in the block must not differ by more than $0.3$.

%I then compare the distribution of RPKMs for genes corresponding
%to TSS covered by segments with $\hat{\theta}<0.5$ with the same distribution
%for genes adjacent to TSS covered by blocks with $\hat{\theta} \geq 0.5$

%\begin{figure}\label{ex3}
%\includegraphics[width=7cm,angle=270]{boxplot_example_3.eps}
%\caption{Segments with different $\hat{\theta}$ overlapping the TSS correspond
%to different distribution of the RPKMs of the corresponding genes.}
%\end{figure}

%\subsection{Demarcation of unusual regions} 

%Next I used \gimli  to look for regions where the 
%methylation
%ratio goes from high to low and to high again.

%In chromosome $1$ of G199, $972$ such intervals intersect one (or more) 
%TSSes. I haven't annotated the remaining ones, but in my view they constitute
%an interesting pattern to look at.

\section{Implementation}

\gimli{} is written in \texttt{C}, and the source
dode is available from the github page of the author. 

\bibliography{gimli_paper}
\bibliographystyle{plain}
\end{document}
